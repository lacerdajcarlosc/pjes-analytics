{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a367c-7c70-427c-8cd5-efff26410014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "\n",
    "# =========================\n",
    "# CONFIGURA√á√ïES\n",
    "# =========================\n",
    "PASTA_ORIGEM = Path(r'2 - CONV√äNIOS')\n",
    "NOME_PLANILHA = 'Planilha de PJES'\n",
    "COMPETENCIA_MANUAL = \"2026-01\"\n",
    "erros = []  # Para registrar erros durante o processamento\n",
    "\n",
    "# =========================\n",
    "# FUN√á√ÉO PARA REGISTRAR ERROS\n",
    "# =========================\n",
    "def registrar_erro(msg_erro):\n",
    "    erros.append(msg_erro)\n",
    "    print(f\"‚ö†Ô∏è {msg_erro}\")\n",
    "\n",
    "# =========================\n",
    "# MAPA COMPLETO DE NORMALIZA√á√ÉO DE CARGOS\n",
    "# =========================\n",
    "MAPA_NORMALIZACAO_CARGOS = {\n",
    "    # Abrevia√ß√µes comuns\n",
    "    'SD': 'SOLDADO',\n",
    "    'SDS': 'SOLDADOS',\n",
    "    'SOLD': 'SOLDADO',\n",
    "    'SOLDAD': 'SOLDADO',\n",
    "    'CB': 'CABO',\n",
    "    'CAB': 'CABO',\n",
    "    'SGT': 'SARGENTO',\n",
    "    'ST': 'SARGENTO',\n",
    "    'SARG': 'SARGENTO',\n",
    "    \n",
    "    # Sargentos com n√∫meros ordinais\n",
    "    '3¬∫ SGT': 'TERCEIRO SARGENTO',\n",
    "    '3 SGT': 'TERCEIRO SARGENTO',\n",
    "    '3¬∫ SARGENTO': 'TERCEIRO SARGENTO',\n",
    "    '3 SARGENTO': 'TERCEIRO SARGENTO',\n",
    "    '3¬∞ SGT': 'TERCEIRO SARGENTO',\n",
    "    '3¬∞ SARGENTO': 'TERCEIRO SARGENTO',\n",
    "    \n",
    "    '2¬∫ SGT': 'SEGUNDO SARGENTO',\n",
    "    '2 SGT': 'SEGUNDO SARGENTO',\n",
    "    '2¬∫ SARGENTO': 'SEGUNDO SARGENTO',\n",
    "    '2 SARGENTO': 'SEGUNDO SARGENTO',\n",
    "    '2¬∞ SGT': 'SEGUNDO SARGENTO',\n",
    "    '2¬∞ SARGENTO': 'SEGUNDO SARGENTO',\n",
    "    \n",
    "    '1¬∫ SGT': 'PRIMEIRO SARGENTO',\n",
    "    '1 SGT': 'PRIMEIRO SARGENTO',\n",
    "    '1¬∫ SARGENTO': 'PRIMEIRO SARGENTO',\n",
    "    '1 SARGENTO': 'PRIMEIRO SARGENTO',\n",
    "    '1¬∞ SGT': 'PRIMEIRO SARGENTO',\n",
    "    '1¬∞ SARGENTO': 'PRIMEIRO SARGENTO',\n",
    "    \n",
    "    # Subtenente\n",
    "    'SUBTEN': 'SUBTENENTE',\n",
    "    'SUB TEN': 'SUBTENENTE',\n",
    "    'SUB-TEN': 'SUBTENENTE',\n",
    "    'STEN': 'SUBTENENTE',\n",
    "    \n",
    "    # Aspirante\n",
    "    'ASP': 'ASPIRANTE A OFICIAL',\n",
    "    'ASP A OF': 'ASPIRANTE A OFICIAL',\n",
    "    'ASPIR': 'ASPIRANTE A OFICIAL',\n",
    "    'ASPIRANTE': 'ASPIRANTE A OFICIAL',\n",
    "    \n",
    "    # Tenentes\n",
    "    '2¬∫ TEN': 'SEGUNDO TENENTE',\n",
    "    '2 TEN': 'SEGUNDO TENENTE',\n",
    "    '2¬∫ TENENTE': 'SEGUNDO TENENTE',\n",
    "    '2 TENENTE': 'SEGUNDO TENENTE',\n",
    "    '2¬∞ TEN': 'SEGUNDO TENENTE',\n",
    "    '2¬∞ TENENTE': 'SEGUNDO TENENTE',\n",
    "    \n",
    "    '1¬∫ TEN': 'PRIMEIRO TENENTE',\n",
    "    '1 TEN': 'PRIMEIRO TENENTE',\n",
    "    '1¬∫ TENENTE': 'PRIMEIRO TENENTE',\n",
    "    '1 TENENTE': 'PRIMEIRO TENENTE',\n",
    "    '1¬∞ TEN': 'PRIMEIRO TENENTE',\n",
    "    '1¬∞ TENENTE': 'PRIMEIRO TENENTE',\n",
    "    \n",
    "    # Capit√£o\n",
    "    'CAP': 'CAPIT√ÉO',\n",
    "    'CAPIT': 'CAPIT√ÉO',\n",
    "    'CAPITAO': 'CAPIT√ÉO',\n",
    "    'CAPT': 'CAPIT√ÉO',\n",
    "    \n",
    "    # Major\n",
    "    'MAJ': 'MAJOR',\n",
    "    \n",
    "    # Tenente Coronel\n",
    "    'TC': 'TENENTE CORONEL',\n",
    "    'TEN CEL': 'TENENTE CORONEL',\n",
    "    'TEN COR': 'TENENTE CORONEL',\n",
    "    'TEN-COR': 'TENENTE CORONEL',\n",
    "    \n",
    "    # Coronel\n",
    "    'CEL': 'CORONEL',\n",
    "    'COR': 'CORONEL',\n",
    "    \n",
    "    # Pol√≠cia Civil / Per√≠cia\n",
    "    'DEL': 'DELEGADO',\n",
    "    'DELEG': 'DELEGADO',\n",
    "    'DELEGADO DE POLICIA': 'DELEGADO DE POL√çCIA CIVIL',\n",
    "    'DELEGADO DE POL CIVIL': 'DELEGADO DE POL√çCIA CIVIL',\n",
    "    'DELEGADO PC': 'DELEGADO DE POL√çCIA CIVIL',\n",
    "    \n",
    "    'PERITO': 'PERITO CRIMINAL',\n",
    "    'PER CRIM': 'PERITO CRIMINAL',\n",
    "    'PERITO CRIM': 'PERITO CRIMINAL',\n",
    "    \n",
    "    'PAPILOSCOPISTA': 'PERITO PAPILOSCOPISTA',\n",
    "    'PER PAP': 'PERITO PAPILOSCOPISTA',\n",
    "    'PERITO PAP': 'PERITO PAPILOSCOPISTA',\n",
    "    \n",
    "    'MED LEG': 'M√âDICO LEGISTA',\n",
    "    'MEDICO LEG': 'M√âDICO LEGISTA',\n",
    "    'MED LEGISTA': 'M√âDICO LEGISTA',\n",
    "    \n",
    "    'AGENTE POL': 'AGENTE DE POL√çCIA',\n",
    "    'AGENTE DE POL': 'AGENTE DE POL√çCIA',\n",
    "    'AG POLICIA': 'AGENTE DE POL√çCIA',\n",
    "    \n",
    "    'ESCRIV': 'ESCRIV√ÉO',\n",
    "    'ESCRIVAO': 'ESCRIV√ÉO',\n",
    "    'ESCRIV√ÉO DE POL': 'ESCRIV√ÉO DE POL√çCIA',\n",
    "    \n",
    "    'AG PERICIA': 'AGENTE DE PER√çCIA CRIMINAL',\n",
    "    'AGENTE PER': 'AGENTE DE PER√çCIA CRIMINAL',\n",
    "    \n",
    "    'AG MED LEGAL': 'AGENTE DE MEDICINA LEGAL',\n",
    "    'AGENTE MED LEGAL': 'AGENTE DE MEDICINA LEGAL',\n",
    "    \n",
    "    # Adicional: remover \"DE\" desnecess√°rio\n",
    "    'DE POLICIA': 'POL√çCIA',\n",
    "    'DE POL√çCIA': 'POL√çCIA',\n",
    "    'DE PERICIA': 'PER√çCIA',\n",
    "    'DE PER√çCIA': 'PER√çCIA',\n",
    "    'DE MEDICINA': 'MEDICINA',\n",
    "}\n",
    "\n",
    "# Mapa de valores por cota (ap√≥s normaliza√ß√£o)\n",
    "MAPA_VALORES_COTA = {\n",
    "    # Pra√ßas - R$ 200\n",
    "    \"SOLDADO\": 200,\n",
    "    \"CABO\": 200,\n",
    "    \"TERCEIRO SARGENTO\": 200,\n",
    "    \"SEGUNDO SARGENTO\": 200,\n",
    "    \"PRIMEIRO SARGENTO\": 200,\n",
    "    \"SUBTENENTE\": 200,\n",
    "    \"AGENTE DE POL√çCIA\": 200,\n",
    "    \"AGENTE DE POL√çCIA CIVIL\": 200,\n",
    "    \"ESCRIV√ÉO DE POL√çCIA\": 200,\n",
    "    \"ESCRIV√ÉO\": 200,\n",
    "    \"AGENTE DE PER√çCIA CRIMINAL\": 200,\n",
    "    \"AGENTE DE MEDICINA LEGAL\": 200,\n",
    "    \n",
    "    # Oficiais - R$ 300\n",
    "    \"ASPIRANTE A OFICIAL\": 300,\n",
    "    \"SEGUNDO TENENTE\": 300,\n",
    "    \"PRIMEIRO TENENTE\": 300,\n",
    "    \"CAPIT√ÉO\": 300,\n",
    "    \"MAJOR\": 300,\n",
    "    \"TENENTE CORONEL\": 300,\n",
    "    \"CORONEL\": 300,\n",
    "    \"DELEGADO DE POL√çCIA CIVIL\": 300,\n",
    "    \"DELEGADO\": 300,\n",
    "    \"PERITO CRIMINAL\": 300,\n",
    "    \"PERITO PAPILOSCOPISTA\": 300,\n",
    "    \"M√âDICO LEGISTA\": 300,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# FUN√á√ïES DE NORMALIZA√á√ÉO DE CARGOS\n",
    "# =========================\n",
    "def normalizar_texto(texto):\n",
    "    \"\"\"Normaliza texto: remove acentos, caracteres especiais, padroniza\"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return ''\n",
    "    \n",
    "    texto = str(texto).upper().strip()\n",
    "    \n",
    "    # Remove acentos\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitui s√≠mbolos de grau\n",
    "    texto = texto.replace('¬∫', ' ').replace('¬∞', ' ').replace('¬™', ' ')\n",
    "    \n",
    "    # Remove caracteres especiais, mantendo letras, n√∫meros e espa√ßos\n",
    "    texto = re.sub(r'[^A-Z0-9\\s]', ' ', texto)\n",
    "    \n",
    "    # Remove m√∫ltiplos espa√ßos\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "def normalizar_cargo_completo(cargo):\n",
    "    \"\"\"Normaliza cargo substituindo todas as abrevia√ß√µes\"\"\"\n",
    "    if pd.isna(cargo):\n",
    "        return 'N√ÉO INFORMADO'\n",
    "    \n",
    "    # Primeiro, normalizar o texto\n",
    "    cargo_norm = normalizar_texto(cargo)\n",
    "    \n",
    "    # print(f\"  Debug - Cargo original: '{cargo}' -> Normalizado: '{cargo_norm}'\")\n",
    "    \n",
    "    # Substituir abrevia√ß√µes (em ordem de especificidade)\n",
    "    # Primeiro procurar por padr√µes espec√≠ficos\n",
    "    for abreviacao, completo in MAPA_NORMALIZACAO_CARGOS.items():\n",
    "        abreviacao_norm = normalizar_texto(abreviacao)\n",
    "        completo_norm = normalizar_texto(completo)\n",
    "        \n",
    "        # Verificar se a abrevia√ß√£o est√° no cargo (como palavra completa)\n",
    "        if abreviacao_norm and cargo_norm == abreviacao_norm:\n",
    "            # print(f\"  Debug - Substitui√ß√£o exata: '{abreviacao_norm}' -> '{completo_norm}'\")\n",
    "            cargo_norm = completo_norm\n",
    "            break\n",
    "        elif abreviacao_norm in cargo_norm.split():\n",
    "            # Substituir a abrevia√ß√£o dentro do texto\n",
    "            cargo_norm = re.sub(rf'\\b{re.escape(abreviacao_norm)}\\b', completo_norm, cargo_norm)\n",
    "            # print(f\"  Debug - Substitui√ß√£o parcial: '{abreviacao_norm}' -> '{completo_norm}' no '{cargo_norm}'\")\n",
    "    \n",
    "    # Garantir que termos importantes estejam completos\n",
    "    termo_substituicoes = {\n",
    "        'POLICIA': 'POL√çCIA',\n",
    "        'PERICIA': 'PER√çCIA',\n",
    "        'MEDICO': 'M√âDICO',\n",
    "        'ESCRIVAO': 'ESCRIV√ÉO',\n",
    "        'CAPITAO': 'CAPIT√ÉO',\n",
    "    }\n",
    "    \n",
    "    for termo_errado, termo_correto in termo_substituicoes.items():\n",
    "        termo_errado_norm = normalizar_texto(termo_errado)\n",
    "        termo_correto_norm = normalizar_texto(termo_correto)\n",
    "        cargo_norm = re.sub(rf'\\b{re.escape(termo_errado_norm)}\\b', termo_correto_norm, cargo_norm)\n",
    "    \n",
    "    # Formatar para t√≠tulo (primeira letra mai√∫scula em cada palavra)\n",
    "    palavras = cargo_norm.split()\n",
    "    cargo_formatado = ' '.join([p.capitalize() for p in palavras])\n",
    "    \n",
    "    # Corre√ß√µes espec√≠ficas para termos compostos\n",
    "    correcoes_especificas = {\n",
    "        'De': 'de',\n",
    "        'Da': 'da',\n",
    "        'Do': 'do',\n",
    "        'A': 'a',\n",
    "        'E': 'e',\n",
    "        'O': 'o',\n",
    "    }\n",
    "    \n",
    "    for palavra, correcao in correcoes_especificas.items():\n",
    "        cargo_formatado = re.sub(rf'\\b{palavra}\\b', correcao, cargo_formatado)\n",
    "    \n",
    "    # Capitalizar primeira letra da string\n",
    "    if cargo_formatado:\n",
    "        cargo_formatado = cargo_formatado[0].upper() + cargo_formatado[1:]\n",
    "    \n",
    "    # print(f\"  Debug - Cargo final: '{cargo_formatado}'\")\n",
    "    return cargo_formatado\n",
    "\n",
    "def obter_valor_por_cota_normalizado(cargo_normalizado):\n",
    "    \"\"\"Retorna o valor da cota baseado no cargo normalizado\"\"\"\n",
    "    if not cargo_normalizado or cargo_normalizado == 'N√ÉO INFORMADO':\n",
    "        return 200  # Valor padr√£o\n",
    "    \n",
    "    cargo_upper = cargo_normalizado.upper()\n",
    "    \n",
    "    # Procurar correspond√™ncia exata\n",
    "    for cargo_padrao, valor in MAPA_VALORES_COTA.items():\n",
    "        if cargo_padrao.upper() in cargo_upper or cargo_upper in cargo_padrao.upper():\n",
    "            # print(f\"  Debug - Valor encontrado para '{cargo_normalizado}': R$ {valor}\")\n",
    "            return valor\n",
    "    \n",
    "    # Heur√≠stica baseada em palavras-chave\n",
    "    palavras_oficial = ['ASPIRANTE', 'TENENTE', 'CAPIT√ÉO', 'MAJOR', 'CORONEL', \n",
    "                       'DELEGADO', 'PERITO', 'M√âDICO', 'PAPILOSCOPISTA']\n",
    "    \n",
    "    palavras_praca = ['SOLDADO', 'CABO', 'SARGENTO', 'SUBTENENTE', \n",
    "                     'AGENTE', 'ESCRIV√ÉO']\n",
    "    \n",
    "    cargo_upper_sem_acentos = unicodedata.normalize('NFKD', cargo_upper).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    for palavra in palavras_oficial:\n",
    "        if palavra in cargo_upper_sem_acentos:\n",
    "            # print(f\"  Debug - Oficial detectado em '{cargo_normalizado}': R$ 300\")\n",
    "            return 300\n",
    "    \n",
    "    for palavra in palavras_praca:\n",
    "        if palavra in cargo_upper_sem_acentos:\n",
    "            # print(f\"  Debug - Pra√ßa detectado em '{cargo_normalizado}': R$ 200\")\n",
    "            return 200\n",
    "    \n",
    "    # print(f\"  Debug - Cargo n√£o encontrado: '{cargo_normalizado}', usando valor padr√£o: R$ 200\")\n",
    "    return 200  # Valor padr√£o\n",
    "\n",
    "# =========================\n",
    "# NORMALIZA√á√ÉO DE COLUNAS\n",
    "# =========================\n",
    "def padronizar_colunas(df):\n",
    "    def normalizar(col):\n",
    "        col = col.strip().upper()\n",
    "        col = unicodedata.normalize('NFKD', col).encode('ASCII', 'ignore').decode('ASCII')\n",
    "        col = re.sub(r'[^A-Z0-9 ]+', '', col)\n",
    "        col = re.sub(r'\\s+', ' ', col)\n",
    "        return col\n",
    "\n",
    "    df.columns = [normalizar(c) for c in df.columns]\n",
    "\n",
    "    mapa = {\n",
    "        'NOME': ['NOME EXTENSO', 'NOME COMPLETO'],\n",
    "        'CARGO': ['CARGO', 'FUNCAO', 'POSTO GRADUACAO'],\n",
    "        'OPERATIVA': ['OPERATIVA', 'UNIDADE', 'LOTACAO'],\n",
    "        'DT TERMINO': ['DT TERMINO', 'DATA TERMINO', 'FIM'],\n",
    "        'DT INICIO': ['DT INICIO', 'DATA INICIO'],\n",
    "        'QTDCOTA': ['QTDCOTA', 'QTD COTA', 'COTA'],\n",
    "        'TITULO': ['TITULO', 'LOCAL', 'EVENTO'],\n",
    "        'MATRICULA': ['MATRICULA'],\n",
    "        'VALOR': ['VALOR', 'VALOR TOTAL', 'VALOR A PAGAR', 'VLR']\n",
    "    }\n",
    "\n",
    "    for padrao, sinonimos in mapa.items():\n",
    "        for col in sinonimos:\n",
    "            if col in df.columns:\n",
    "                df.rename(columns={col: padrao}, inplace=True)\n",
    "                break\n",
    "\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# COMPET√äNCIA / EXERC√çCIO\n",
    "# =========================\n",
    "MAPA_MESES = {\n",
    "    1: 'JANEIRO',\n",
    "    2: 'FEVEREIRO',\n",
    "    3: 'MAR√áO',\n",
    "    4: 'ABRIL',\n",
    "    5: 'MAIO',\n",
    "    6: 'JUNHO',\n",
    "    7: 'JULHO',\n",
    "    8: 'AGOSTO',\n",
    "    9: 'SETEMBRO',\n",
    "    10: 'OUTUBRO',\n",
    "    11: 'NOVEMBRO',\n",
    "    12: 'DEZEMBRO'\n",
    "}\n",
    "\n",
    "def extrair_competencia(nome_arquivo):\n",
    "    # Se houver compet√™ncia manual definida, usa ela\n",
    "    if COMPETENCIA_MANUAL:\n",
    "        try:\n",
    "            ano, mes = COMPETENCIA_MANUAL.split(\"-\")\n",
    "            return datetime(int(ano), int(mes), 1)\n",
    "        except Exception:\n",
    "            print(\"‚ö†Ô∏è COMPETENCIA_MANUAL inv√°lida. Use o formato AAAA-MM, ex: 2026-01\")\n",
    "            return datetime.today().replace(day=1)\n",
    "\n",
    "    # Caso contr√°rio, continua usando o nome do arquivo (modo autom√°tico)\n",
    "    nome = nome_arquivo.upper()\n",
    "    mes = None\n",
    "    ano = None\n",
    "\n",
    "    for m in MAPA_MESES:\n",
    "        if m in nome:\n",
    "            mes = MAPA_MESES[m]\n",
    "            break\n",
    "\n",
    "    ano_match = re.search(r'20\\d{2}', nome)\n",
    "    if ano_match:\n",
    "        ano = int(ano_match.group())\n",
    "\n",
    "    if mes and ano:\n",
    "        return datetime(ano, mes, 1)\n",
    "\n",
    "    return datetime.today().replace(day=1)\n",
    "\n",
    "# =========================\n",
    "# FUN√á√ÉO PARA CALCULAR VERBA\n",
    "# =========================\n",
    "\n",
    "def calcular_verba(data_fim, competencia):\n",
    "    if pd.isna(data_fim):   \n",
    "        return ''\n",
    "    data_fim = pd.to_datetime(data_fim) \n",
    "    competencia = pd.to_datetime(competencia) \n",
    "    inicio_comp = competencia.replace(day=1)\n",
    "    if data_fim.year == competencia.year and data_fim.month == competencia.month:\n",
    "        return 223\n",
    "    elif data_fim < inicio_comp:\n",
    "        return 423\n",
    "    return ''\n",
    "\n",
    "# =========================\n",
    "# FUN√á√ÉO PARA CALCULAR VALOR\n",
    "# =========================\n",
    "def calcular_valor_com_cota_normalizado(row):\n",
    "    \"\"\"Calcula o valor baseado na cota e no cargo normalizado\"\"\"\n",
    "    try:\n",
    "        # Primeiro, tentar usar o valor existente na planilha\n",
    "        if 'VALOR' in row.index and not pd.isna(row['VALOR']):\n",
    "            try:\n",
    "                valor = float(row['VALOR'])\n",
    "                if valor > 0:\n",
    "                    return valor\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Se n√£o houver valor ou for inv√°lido, calcular baseado na cota e cargo normalizado\n",
    "        if 'QTDCOTA' in row.index and 'CARGO NORMALIZADO' in row.index:\n",
    "            cota = pd.to_numeric(row['QTDCOTA'], errors='coerce')\n",
    "            cargo_normalizado = row['CARGO NORMALIZADO']\n",
    "            \n",
    "            if not pd.isna(cota) and cota > 0:\n",
    "                valor_por_cota = obter_valor_por_cota_normalizado(cargo_normalizado)\n",
    "                valor_total = cota * valor_por_cota\n",
    "                return round(valor_total, 2)\n",
    "        \n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"  Erro ao calcular valor: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# =========================\n",
    "# PROCESSAMENTO DE ARQUIVO COM NORMALIZA√á√ÉO\n",
    "# =========================\n",
    "def processar_arquivo(arquivo):\n",
    "    try:\n",
    "        print(f\"üìÑ Processando: {arquivo.name}\")\n",
    "        \n",
    "        # Extrair compet√™ncia do nome do arquivo\n",
    "        competencia_data = extrair_competencia(arquivo.name)\n",
    "        \n",
    "        # Ler o arquivo Excel\n",
    "        df = pd.read_excel(\n",
    "            arquivo,\n",
    "            sheet_name=NOME_PLANILHA,\n",
    "            skiprows=9,\n",
    "            usecols=\"A:L\",\n",
    "            engine='openpyxl'\n",
    "        )\n",
    "        \n",
    "        # Remover linhas completamente vazias\n",
    "        df.dropna(how='all', inplace=True)\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(f\"   ‚ö†Ô∏è Arquivo vazio ou sem dados ap√≥s linha 9\")\n",
    "            return None\n",
    "        \n",
    "        # Padronizar colunas\n",
    "        df = padronizar_colunas(df)\n",
    "        \n",
    "        # Tratamento de dados\n",
    "        if 'DT TERMINO' in df.columns:\n",
    "            df['DT TERMINO'] = pd.to_datetime(df['DT TERMINO'], errors='coerce', dayfirst=True)\n",
    "        else:\n",
    "            df['DT TERMINO'] = pd.NaT\n",
    "        \n",
    "        # NORMALIZAR CARGOS\n",
    "        print(f\"   üîß Normalizando cargos...\")\n",
    "        if 'CARGO' in df.columns:\n",
    "            # Manter o cargo original para refer√™ncia\n",
    "            df['CARGO ORIGINAL'] = df['CARGO'].astype(str).str.strip()\n",
    "            \n",
    "            # Aplicar normaliza√ß√£o completa\n",
    "            df['CARGO NORMALIZADO'] = df['CARGO'].apply(normalizar_cargo_completo)\n",
    "            \n",
    "            # Usar o cargo normalizado como principal\n",
    "            df['CARGO'] = df['CARGO NORMALIZADO']\n",
    "            \n",
    "            # Estat√≠sticas de normaliza√ß√£o\n",
    "            cargos_unicos = df['CARGO ORIGINAL'].nunique()\n",
    "            cargos_normais_unicos = df['CARGO NORMALIZADO'].nunique()\n",
    "            print(f\"   üìä Cargos √∫nicos: {cargos_unicos} ‚Üí {cargos_normais_unicos} (normalizados)\")\n",
    "        else:\n",
    "            df['CARGO'] = 'N√ÉO INFORMADO'\n",
    "            df['CARGO ORIGINAL'] = 'N√ÉO INFORMADO'\n",
    "            df['CARGO NORMALIZADO'] = 'N√ÉO INFORMADO'\n",
    "        \n",
    "        if 'QTDCOTA' in df.columns:\n",
    "            df['QTDCOTA'] = pd.to_numeric(df['QTDCOTA'], errors='coerce').fillna(0)\n",
    "        else:\n",
    "            df['QTDCOTA'] = 0\n",
    "        \n",
    "        # Calcular VALOR usando cargos normalizados\n",
    "        print(f\"   üí∞ Calculando valores...\")\n",
    "        df['VALOR'] = df.apply(calcular_valor_com_cota_normalizado, axis=1)\n",
    "        \n",
    "        df['EXERC√çCIO'] = competencia_data.year \n",
    "        \n",
    "        mes_numero = competencia_data.month\n",
    "        df['COMPET√äNCIA'] = MAPA_MESES.get(mes_numero, '').upper()\n",
    "\n",
    "        df['ORIGEM COTA'] = 'DECRETO'\n",
    "        df['ORIGEM DA INFORMA√á√ÉO'] = arquivo.name.replace('.xlsx', '')\n",
    "        \n",
    "        # Verificar se as colunas existem antes de us√°-las\n",
    "        if 'OPERATIVA' in df.columns:\n",
    "            df['OPERATIVA QUE PRESTOU SERVI√áO'] = df['OPERATIVA']\n",
    "        else:\n",
    "            df['OPERATIVA QUE PRESTOU SERVI√áO'] = ''\n",
    "            \n",
    "        if 'TITULO' in df.columns:\n",
    "            df['LOCAL DA PRESTA√á√ÉO DO SERVI√áO'] = df['TITULO']\n",
    "        else:\n",
    "            df['LOCAL DA PRESTA√á√ÉO DO SERVI√áO'] = ''\n",
    "        \n",
    "        df['COTA'] = df['QTDCOTA'].astype(int)\n",
    "        \n",
    "        if 'DT TERMINO' in df.columns:\n",
    "            df['VERBA'] = df['DT TERMINO'].apply(lambda x: calcular_verba(x, competencia_data))\n",
    "        else:\n",
    "            df['VERBA'] = ''\n",
    "        \n",
    "        df['SITUA√á√ÉO'] = 'ATIVO'\n",
    "        \n",
    "        # Tratar matr√≠cula\n",
    "        if 'MATRICULA' in df.columns:\n",
    "            df['MATRICULA'] = df['MATRICULA'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "        else:\n",
    "            df['MATRICULA'] = ''\n",
    "        \n",
    "        # Verificar qual coluna de nome usar\n",
    "        if 'NOME' in df.columns:\n",
    "            df['NOME'] = df['NOME']\n",
    "        elif 'NOME EXTENSO' in df.columns:\n",
    "            df['NOME'] = df['NOME EXTENSO']\n",
    "        elif 'NOME COMPLETO' in df.columns:\n",
    "            df['NOME'] = df['NOME COMPLETO']\n",
    "        else:\n",
    "            # Tentar encontrar coluna que contenha 'NOME'\n",
    "            coluna_nome = [c for c in df.columns if 'NOME' in c]\n",
    "            if coluna_nome:\n",
    "                df['NOME'] = df[coluna_nome[0]]\n",
    "            else:\n",
    "                df['NOME'] = ''\n",
    "        \n",
    "        # Adicionar valor por cota para an√°lise\n",
    "        df['VALOR POR COTA'] = df['CARGO NORMALIZADO'].apply(obter_valor_por_cota_normalizado)\n",
    "        \n",
    "        # Estat√≠sticas do processamento\n",
    "        valor_total = df['VALOR'].sum()\n",
    "        print(f\"   ‚úÖ {len(df)} registros processados\")\n",
    "        print(f\"   üí∞ Valor total calculado: R$ {valor_total:,.2f}\")\n",
    "        print(f\"   üìä Valor m√©dio por cota: R$ {df['VALOR POR COTA'].mean():.2f}\")\n",
    "        \n",
    "        # Mostrar alguns exemplos de normaliza√ß√£o\n",
    "        if 'CARGO ORIGINAL' in df.columns and 'CARGO NORMALIZADO' in df.columns:\n",
    "            exemplos = df[['CARGO ORIGINAL', 'CARGO NORMALIZADO', 'VALOR POR COTA']].drop_duplicates().head(3)\n",
    "            print(f\"   üìù Exemplos de normaliza√ß√£o:\")\n",
    "            for idx, row in exemplos.iterrows():\n",
    "                print(f\"     '{row['CARGO ORIGINAL']}' ‚Üí '{row['CARGO NORMALIZADO']}' (R$ {row['VALOR POR COTA']}/cota)\")\n",
    "        \n",
    "        # Organizar colunas finais\n",
    "        colunas_finais = [\n",
    "            'EXERC√çCIO', 'COMPET√äNCIA', 'ORIGEM COTA', 'ORIGEM DA INFORMA√á√ÉO',\n",
    "            'OPERATIVA QUE PRESTOU SERVI√áO', 'LOCAL DA PRESTA√á√ÉO DO SERVI√áO',\n",
    "            'MATRICULA', 'NOME', 'COTA', 'VERBA', 'CARGO', 'SITUA√á√ÉO', 'VALOR',\n",
    "            'VALOR POR COTA', 'CARGO NORMALIZADO', 'CARGO ORIGINAL'\n",
    "        ]\n",
    "        \n",
    "        # Garantir que todas as colunas existam\n",
    "        for col in colunas_finais:\n",
    "            if col not in df.columns:\n",
    "                df[col] = ''\n",
    "                \n",
    "        df_final = df[colunas_finais].copy()\n",
    "\n",
    "        # juntar colunas originais com as finais\n",
    "        df_completo = pd.concat([df, df_final], axis=1)\n",
    "        \n",
    "        # remover duplicadas mantendo a primeira ocorr√™ncia\n",
    "        df_completo = df_completo.loc[:, ~df_completo.columns.duplicated()]\n",
    "        \n",
    "        return df_final, df_completo\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "        msg_erro = f\"Erro ao processar o arquivo '{arquivo.name}': {str(e)}\"\n",
    "        registrar_erro(msg_erro)\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# RELAT√ìRIO DE NORMALIZA√á√ÉO\n",
    "# =========================\n",
    "def gerar_relatorio_normalizacao(df):\n",
    "    \"\"\"Gera um relat√≥rio detalhado da normaliza√ß√£o de cargos\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìã RELAT√ìRIO DE NORMALIZA√á√ÉO DE CARGOS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Agrupar cargos originais e normalizados\n",
    "    relatorio_cargos = df.groupby(['CARGO ORIGINAL', 'CARGO NORMALIZADO', 'VALOR POR COTA']).agg({\n",
    "        'NOME': 'count',\n",
    "        'VALOR': 'sum',\n",
    "        'COTA': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    relatorio_cargos = relatorio_cargos.rename(columns={\n",
    "        'NOME': 'QUANTIDADE',\n",
    "        'VALOR': 'TOTAL VALOR (R$)',\n",
    "        'COTA': 'TOTAL COTAS'\n",
    "    })\n",
    "    \n",
    "    # Ordenar por quantidade\n",
    "    relatorio_cargos = relatorio_cargos.sort_values('QUANTIDADE', ascending=False)\n",
    "    \n",
    "    print(\"Principais transforma√ß√µes:\")\n",
    "    print(\"-\" * 70)\n",
    "    for idx, row in relatorio_cargos.head(10).iterrows():\n",
    "        print(f\"'{row['CARGO ORIGINAL']}' ‚Üí '{row['CARGO NORMALIZADO']}'\")\n",
    "        print(f\"  R$ {row['VALOR POR COTA']}/cota | {row['QUANTIDADE']} pessoas | {row['TOTAL COTAS']} cotas | R$ {row['TOTAL VALOR (R$)']:,.2f}\")\n",
    "        print()\n",
    "    \n",
    "    # Resumo por valor por cota\n",
    "    print(\"\\nüìä RESUMO POR VALOR DE COTA:\")\n",
    "    print(\"-\" * 50)\n",
    "    resumo_valor = df.groupby('VALOR POR COTA').agg({\n",
    "        'NOME': 'count',\n",
    "        'VALOR': 'sum',\n",
    "        'COTA': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    for idx, row in resumo_valor.iterrows():\n",
    "        valor_cota = row['VALOR POR COTA']\n",
    "        qtd = row['NOME']\n",
    "        total_valor = row['VALOR']\n",
    "        total_cotas = row['COTA']\n",
    "        print(f\"R$ {valor_cota}/cota: {qtd} pessoas, {total_cotas} cotas, R$ {total_valor:,.2f}\")\n",
    "\n",
    "# =========================\n",
    "# PROCESSAMENTO PRINCIPAL\n",
    "# =========================\n",
    "def processar_pasta(pasta):\n",
    "    completos = []\n",
    "    dfs = []\n",
    "    \n",
    "    # Verificar se a pasta existe\n",
    "    if not pasta.exists():\n",
    "        print(f\"‚ùå Pasta n√£o encontrada: {pasta}\")\n",
    "        return None\n",
    "    \n",
    "    # Processar todos os arquivos Excel na pasta\n",
    "    arquivos = list(pasta.glob('*.xlsx'))\n",
    "    print(f\"üìÅ Encontrados {len(arquivos)} arquivos Excel em {pasta}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for arquivo in arquivos:\n",
    "        resultado = processar_arquivo(arquivo)\n",
    "    \n",
    "        if resultado is not None:\n",
    "            resultado_df, completo_df = resultado\n",
    "            dfs.append(resultado_df)\n",
    "            completos.append(completo_df)\n",
    "    \n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    \n",
    "    # Combinar todos os DataFrames\n",
    "    if dfs:\n",
    "        data = pd.concat(dfs, ignore_index=True)\n",
    "        dados_completos = pd.concat(completos, ignore_index=True)\n",
    "        data['COTA'] = pd.to_numeric(data['COTA'], errors='coerce').fillna(0)\n",
    "        data['VALOR'] = pd.to_numeric(data['VALOR'], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Gerar relat√≥rio de normaliza√ß√£o\n",
    "        gerar_relatorio_normalizacao(data)\n",
    "        \n",
    "        # Agrupar dados para o resultado final\n",
    "        colunas_agrupamento = [\n",
    "            'EXERC√çCIO', 'COMPET√äNCIA', 'ORIGEM COTA', 'ORIGEM DA INFORMA√á√ÉO',\n",
    "            'OPERATIVA QUE PRESTOU SERVI√áO', 'LOCAL DA PRESTA√á√ÉO DO SERVI√áO',\n",
    "            'MATRICULA', 'NOME', 'VERBA', 'CARGO NORMALIZADO', 'SITUA√á√ÉO'\n",
    "        ]\n",
    "        \n",
    "        # Garantir que todas as colunas de agrupamento existam\n",
    "        colunas_agrupamento = [col for col in colunas_agrupamento if col in data.columns]\n",
    "        \n",
    "        data_agrupado = data.groupby(colunas_agrupamento, as_index=False).agg({\n",
    "            'COTA': 'sum',\n",
    "            'VALOR': 'sum',\n",
    "            'VALOR POR COTA': 'first',\n",
    "            'CARGO ORIGINAL': lambda x: '; '.join(set(x)) if len(set(x)) <= 3 else f\"{len(set(x))} varia√ß√µes\"\n",
    "        }).sort_values(by='VALOR', ascending=False)\n",
    "        \n",
    "        return data_agrupado, dados_completos\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum arquivo foi processado com sucesso.\")\n",
    "        return None, None\n",
    "\n",
    "# =========================\n",
    "# EXECU√á√ÉO PRINCIPAL\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Iniciando processamento de arquivos PJES com normaliza√ß√£o de cargos...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    resultado, dados_completos = processar_pasta(PASTA_ORIGEM)\n",
    "    \n",
    "    if resultado is not None:\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(\"‚úÖ PROCESSAMENTO CONCLU√çDO COM NORMALIZA√á√ÉO DE CARGOS!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üìä Total de registros √∫nicos: {len(resultado):,}\")\n",
    "        print(f\"üìä Total de cotas: {resultado['COTA'].sum():,.0f}\")\n",
    "        print(f\"üí∞ Total de valor: R$ {resultado['VALOR'].sum():,.2f}\")\n",
    "        \n",
    "        # Estat√≠sticas por tipo de cargo\n",
    "        print(f\"\\nüìà DISTRIBUI√á√ÉO POR VALOR DE COTA:\")\n",
    "        for valor_cota in sorted(resultado['VALOR POR COTA'].unique()):\n",
    "            subset = resultado[resultado['VALOR POR COTA'] == valor_cota]\n",
    "            print(f\"   ‚Ä¢ R$ {valor_cota}/cota: {len(subset):,} pessoas, R$ {subset['VALOR'].sum():,.2f}\")\n",
    "        \n",
    "        # Salvar resultado consolidado\n",
    "        arquivo_saida = PASTA_ORIGEM / 'PJES_CONSOLIDADO_NORMALIZADO.xlsx'\n",
    "        resultado.to_excel(arquivo_saida, index=False)\n",
    "        print(f\"\\nüíæ Resultado consolidado salvo em: {arquivo_saida}\")\n",
    "        \n",
    "        # Salvar dados completos\n",
    "        if dados_completos is not None:\n",
    "            arquivo_completo = PASTA_ORIGEM / 'PJES_DADOS_COMPLETOS_NORMALIZADOS.xlsx'\n",
    "            dados_completos.to_excel(arquivo_completo, index=False)\n",
    "            print(f\"üíæ Dados completos salvos em: {arquivo_completo}\")\n",
    "        \n",
    "        # Mostrar amostra dos dados\n",
    "        print(f\"\\nüìã AMOSTRA DOS DADOS NORMALIZADOS (5 maiores valores):\")\n",
    "        amostra = resultado[['NOME', 'CARGO NORMALIZADO', 'VALOR POR COTA', 'COTA', 'VALOR']].head()\n",
    "        print(amostra.to_string(index=False))\n",
    "        \n",
    "        # Mostrar erros se houver\n",
    "        if erros:\n",
    "            print(f\"\\n‚ö†Ô∏è {len(erros)} erro(s) encontrado(s):\")\n",
    "            for i, erro in enumerate(erros[:3], 1):\n",
    "                print(f\"   {i}. {erro}\")\n",
    "            if len(erros) > 3:\n",
    "                print(f\"   ... e mais {len(erros) - 3} erros\")\n",
    "                \n",
    "        # Salvar log de erros\n",
    "        if erros:\n",
    "            log_erros = PASTA_ORIGEM / 'PJES_ERROS_LOG.txt'\n",
    "            with open(log_erros, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"LOG DE ERROS - PROCESSAMENTO PJES COM NORMALIZA√á√ÉO\\n\")\n",
    "                f.write(\"=\" * 60 + \"\\n\")\n",
    "                for erro in erros:\n",
    "                    f.write(f\"‚Ä¢ {erro}\\n\")\n",
    "            print(f\"\\nüìù Log de erros salvo em: {log_erros}\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Nenhum dado foi processado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
